{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b60eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import sys\n",
    "import inference_pb2_grpc as pb2_grpc\n",
    "import inference_pb2 as pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f32f5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile proto3 file\n",
    "# python3 -m grpc_tools.protoc --proto_path=. ./inference.proto --python_out=. --grpc_python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003941c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestClient(object):\n",
    "    \"\"\"\n",
    "    Client for testing inference gRPC\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        #self.host = '3.139.238.241'\n",
    "        self.host = 'localhost'\n",
    "        self.server_port = 5125\n",
    "\n",
    "        # instantiate a channel\n",
    "        self.channel = grpc.insecure_channel(\n",
    "            '{}:{}'.format(self.host, self.server_port))\n",
    "\n",
    "        # bind the client and the server\n",
    "        self.stub = pb2_grpc.InferenceStub(self.channel)\n",
    "\n",
    "    def send(self, tx, modelHash, modelInput):\n",
    "        \"\"\"\n",
    "        Client function to call the rpc for inference\n",
    "        \"\"\"\n",
    "        message = pb2.InferenceParameters(tx=tx, modelHash=modelHash, modelInput = modelInput)\n",
    "        print(f'{message}')\n",
    "        return self.stub.RunInference(message)\n",
    "    \n",
    "    def pipeline(self, tx, seed, pipelineName, modelHash, modelInput):\n",
    "        \"\"\"\n",
    "        Client function to call the rpc for inference\n",
    "        \"\"\"\n",
    "        message = pb2.PipelineParameters(tx=tx, seed=seed, pipelineName=pipelineName, modelHash=modelHash, modelInput = modelInput)\n",
    "        return self.stub.RunPipeline(message)\n",
    "\n",
    "def testLinearModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"LinearTest\", modelInput=\"[[1.0, 2.0, 3.0], [2.5, 3.5, 4.5]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "\n",
    "def testVolatilityModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"Volatility.onnx\", modelInput=\"[[0.03],[0.05],[0.04056685],[0.03235871],[0.05629578]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testXGBSpreadModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"XGBSpreadModel\", modelInput=\"[[0.003], [0.005], [0.004056685]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "\n",
    "def testLassoSpreadModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"QmXQpupTphRTeXJMEz3BCt9YUF6kikcqExxPdcVoL1BBhy\", modelInput=\"[[0.003, 0.005, 0.004056685]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testPipeline():\n",
    "    client = TestClient()\n",
    "    result = client.pipeline(tx = \"0x123\", seed=\"2\", pipelineName=\"text-generation\", modelHash=\"gpt2-xl\", modelInput=\"Please write me a poem about crypto?\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cb0788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx: \"0x123\"\n",
      "modelHash: \"Volatility.onnx\"\n",
      "modelInput: \"[[0.03],[0.05],[0.04056685],[0.03235871],[0.05629578]]\"\n",
      "\n"
     ]
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception calling application: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from Volatility.onnx failed:Load model Volatility.onnx failed. File doesn't exist\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2023-09-29T14:07:35.729537-04:00\", grpc_status:2, grpc_message:\"Exception calling application: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from Volatility.onnx failed:Load model Volatility.onnx failed. File doesn\\'t exist\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-38e3bb50da6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestVolatilityModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-10fb1ab681ce>\u001b[0m in \u001b[0;36mtestVolatilityModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtestVolatilityModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0x123\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelHash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Volatility.onnx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelInput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"[[0.03],[0.05],[0.04056685],[0.03235871],[0.05629578]]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Querying \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\":\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_port\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{result}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-10fb1ab681ce>\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, tx, modelHash, modelInput)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceParameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelHash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelHash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{message}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipelineName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelHash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001b[1;32m   1029\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     def with_call(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception calling application: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from Volatility.onnx failed:Load model Volatility.onnx failed. File doesn't exist\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2023-09-29T14:07:35.729537-04:00\", grpc_status:2, grpc_message:\"Exception calling application: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from Volatility.onnx failed:Load model Volatility.onnx failed. File doesn\\'t exist\"}\"\n>"
     ]
    }
   ],
   "source": [
    "testVolatilityModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf89bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx: \"0x123\"\n",
      "modelHash: \"XGBSpreadModel\"\n",
      "modelInput: \"[[0.003], [0.005], [0.004056685]]\"\n",
      "\n"
     ]
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception calling application: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from XGBSpreadModel failed:Load model XGBSpreadModel failed. File doesn't exist\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"Exception calling application: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from XGBSpreadModel failed:Load model XGBSpreadModel failed. File doesn\\'t exist\", grpc_status:2, created_time:\"2023-09-29T14:07:36.496053-04:00\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9389414f6953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestXGBSpreadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-10fb1ab681ce>\u001b[0m in \u001b[0;36mtestXGBSpreadModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtestXGBSpreadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTestClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"0x123\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelHash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"XGBSpreadModel\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelInput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"[[0.003], [0.005], [0.004056685]]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Querying \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\":\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_port\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{result}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-10fb1ab681ce>\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, tx, modelHash, modelInput)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceParameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelHash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelHash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{message}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipelineName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelHash\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001b[1;32m   1029\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     def with_call(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNKNOWN\n\tdetails = \"Exception calling application: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from XGBSpreadModel failed:Load model XGBSpreadModel failed. File doesn't exist\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"Exception calling application: [ONNXRuntimeError] : 3 : NO_SUCHFILE : Load model from XGBSpreadModel failed:Load model XGBSpreadModel failed. File doesn\\'t exist\", grpc_status:2, created_time:\"2023-09-29T14:07:36.496053-04:00\"}\"\n>"
     ]
    }
   ],
   "source": [
    "testXGBSpreadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb38803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx: \"0x123\"\n",
      "modelHash: \"QmXQpupTphRTeXJMEz3BCt9YUF6kikcqExxPdcVoL1BBhy\"\n",
      "modelInput: \"[[0.003, 0.005, 0.004056685]]\"\n",
      "\n",
      "Querying localhost:5125...\n",
      "tx: \"0x123\"\n",
      "node: \"9b438110500ab13fcd0397901332bcac12c5ff4e08f72dd0107acf8d60892a1b34350c7703c52baae1696c2e3229cbadaad4c0d81aefcf115456e3daafb0a519\"\n",
      "value: \"0.001360592\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testLassoSpreadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1c33a640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying localhost:5127...\n",
      "tx: \"0x123\"\n",
      "node: \"gpt2-xl\"\n",
      "value: \"Please write me a poem about crypto?\\n\\n\\nIf you have an internet connection and want to learn about Bitcoin, please write me an email here:\\n\\n\\nIn any case, I am here to help anyone as much as I can!I do\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testPipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
