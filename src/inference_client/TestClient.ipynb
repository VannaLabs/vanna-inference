{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b60eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import sys\n",
    "import inference_pb2_grpc as pb2_grpc\n",
    "import inference_pb2 as pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32f5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile proto3 file\n",
    "# python3 -m grpc_tools.protoc --proto_path=. ./inference.proto --python_out=. --grpc_python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "003941c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestClient(object):\n",
    "    \"\"\"\n",
    "    Client for testing inference gRPC\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.host = '3.139.238.241'\n",
    "        #self.host = 'localhost'\n",
    "        self.server_port = 5125\n",
    "\n",
    "        # instantiate a channel\n",
    "        self.channel = grpc.insecure_channel(\n",
    "            '{}:{}'.format(self.host, self.server_port))\n",
    "\n",
    "        # bind the client and the server\n",
    "        self.stub = pb2_grpc.InferenceStub(self.channel)\n",
    "\n",
    "    def send(self, tx, modelHash, modelInput):\n",
    "        \"\"\"\n",
    "        Client function to call the rpc for inference\n",
    "        \"\"\"\n",
    "        message = pb2.InferenceParameters(tx=tx, modelHash=modelHash, modelInput = modelInput)\n",
    "        print(f'{message}')\n",
    "        return self.stub.RunInference(message)\n",
    "    \n",
    "    def pipeline(self, tx, seed, pipelineName, modelHash, modelInput):\n",
    "        \"\"\"\n",
    "        Client function to call the rpc for inference\n",
    "        \"\"\"\n",
    "        message = pb2.PipelineParameters(tx=tx, seed=seed, pipelineName=pipelineName, modelHash=modelHash, modelInput = modelInput)\n",
    "        return self.stub.RunPipeline(message)\n",
    "\n",
    "def testLinearModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"LinearTest\", modelInput=\"[[1.0, 2.0, 3.0], [2.5, 3.5, 4.5]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "\n",
    "def testVolatilityModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"Volatility.onnx\", modelInput=\"[[0.03],[0.05],[0.04056685],[0.03235871],[0.05629578]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testXGBSpreadModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"XGBSpreadModel\", modelInput=\"[[0.003], [0.005], [0.004056685]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "\n",
    "def testLassoSpreadModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"QmXQpupTphRTeXJMEz3BCt9YUF6kikcqExxPdcVoL1BBhy\", modelInput=\"[[0.003, 0.005, 0.004056685]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testPipeline():\n",
    "    client = TestClient()\n",
    "    result = client.pipeline(tx = \"0x123\", seed=\"2\", pipelineName=\"text-generation\", modelHash=\"gpt2-xl\", modelInput=\"Please write me a poem about crypto?\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testClusteringModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"QmYrQvh6ixW1oQUK5Lehjmqk5eSsthiUXwQVFQA7BDf9yv\", modelInput=\"[[0.001410,1.003477,0.007010]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testVolModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"QmcDnBi5PT223FmELECbZVTjitFUtTvaBoctDP88ESuAK4\", modelInput=\"[[0.003, 0.005, 0.004056685],[0.001410,0.003477,0.007010]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "381e5426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx: \"0x123\"\n",
      "modelHash: \"QmYrQvh6ixW1oQUK5Lehjmqk5eSsthiUXwQVFQA7BDf9yv\"\n",
      "modelInput: \"[[0,7.314236392868128e-18,0.000005091525349575833]]\"\n",
      "\n"
     ]
    },
    {
     "ename": "_InactiveRpcError",
     "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"recvmsg:Operation timed out\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2023-10-22T11:03:30.207073-04:00\", grpc_status:14, grpc_message:\"recvmsg:Operation timed out\"}\"\n>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testClusteringModel()\n",
      "Cell \u001b[0;32mIn[62], line 65\u001b[0m, in \u001b[0;36mtestClusteringModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtestClusteringModel\u001b[39m():\n\u001b[1;32m     64\u001b[0m     client \u001b[38;5;241m=\u001b[39m TestClient()\n\u001b[0;32m---> 65\u001b[0m     result \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39msend(tx \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0x123\u001b[39m\u001b[38;5;124m\"\u001b[39m, modelHash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQmYrQvh6ixW1oQUK5Lehjmqk5eSsthiUXwQVFQA7BDf9yv\u001b[39m\u001b[38;5;124m\"\u001b[39m, modelInput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[[0,7.314236392868128e-18,0.000005091525349575833]]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuerying \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m client\u001b[38;5;241m.\u001b[39mhost \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(client\u001b[38;5;241m.\u001b[39mserver_port) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[62], line 24\u001b[0m, in \u001b[0;36mTestClient.send\u001b[0;34m(self, tx, modelHash, modelInput)\u001b[0m\n\u001b[1;32m     22\u001b[0m message \u001b[38;5;241m=\u001b[39m pb2\u001b[38;5;241m.\u001b[39mInferenceParameters(tx\u001b[38;5;241m=\u001b[39mtx, modelHash\u001b[38;5;241m=\u001b[39mmodelHash, modelInput \u001b[38;5;241m=\u001b[39m modelInput)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstub\u001b[38;5;241m.\u001b[39mRunInference(message)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/grpc/_channel.py:1161\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1148\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1154\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1155\u001b[0m     (\n\u001b[1;32m   1156\u001b[0m         state,\n\u001b[1;32m   1157\u001b[0m         call,\n\u001b[1;32m   1158\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1159\u001b[0m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1160\u001b[0m     )\n\u001b[0;32m-> 1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/grpc/_channel.py:1004\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m state\u001b[38;5;241m.\u001b[39mresponse\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1004\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"recvmsg:Operation timed out\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2023-10-22T11:03:30.207073-04:00\", grpc_status:14, grpc_message:\"recvmsg:Operation timed out\"}\"\n>"
     ]
    }
   ],
   "source": [
    "testClusteringModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c15ebaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx: \"0x123\"\n",
      "modelHash: \"QmcDnBi5PT223FmELECbZVTjitFUtTvaBoctDP88ESuAK4\"\n",
      "modelInput: \"[[0.003, 0.005, 0.004056685],[0.001410,0.003477,0.007010]]\"\n",
      "\n",
      "Querying 3.139.238.241:5125...\n",
      "tx: \"0x123\"\n",
      "node: \"664a198a8c4f622ebfcf2e8c40887994e79b59e3ecafe2bf3f2d3d72e1d752b7c0f0fc4ff0bd2208942cea0d613e148c92a7c17f06ec561b505d61dfa6a1e6d0\"\n",
      "value: \"0.002743951\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testVolModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95bfd9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx: \"0x123\"\n",
      "modelHash: \"QmXQpupTphRTeXJMEz3BCt9YUF6kikcqExxPdcVoL1BBhy\"\n",
      "modelInput: \"[[0.003, 0.005, 0.004056685]]\"\n",
      "\n",
      "Querying 3.139.238.241:5125...\n",
      "tx: \"0x123\"\n",
      "node: \"c08e55da00fd932e7ba22792b650b99b520a1288882d58a505bfca53bbebb84e9d6910f61bbeb897da850d8c7171b7469fca999900e3dc6f1f0a8d17ccde912c\"\n",
      "value: \"0.001360592\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testLassoSpreadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1369fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
