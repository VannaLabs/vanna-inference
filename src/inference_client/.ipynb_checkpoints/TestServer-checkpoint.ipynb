{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c633ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import sys\n",
    "from concurrent import futures\n",
    "import inference_pb2_grpc \n",
    "import onnx\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import inference_pb2 \n",
    "import ezkl\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "379b326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceServer(inference_pb2_grpc.InferenceServicer):\n",
    "    def RunInference(self, inferenceParams, context):\n",
    "        results = self.Infer(inferenceParams.modelHash, inferenceParams.modelInput)\n",
    "        return inference_pb2.InferenceResult(tx=inferenceParams.tx, node=inferenceParams.modelHash, value=str(results))\n",
    "    \n",
    "    def Infer(self, modelHash, modelInput):\n",
    "        session = onnxruntime.InferenceSession(modelHash)\n",
    "        results = session.run(curateOutputs(session), curateInputs(session, modelInput))[-1]\n",
    "        return results[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32106209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serve(port, maxWorkers):\n",
    "    server = grpc.server(futures.ThreadPoolExecutor(max_workers=maxWorkers))\n",
    "    inference_pb2_grpc.add_InferenceServicer_to_server(InferenceServer(), server)\n",
    "    server.add_insecure_port(\"[::]:\" + str(port))\n",
    "    server.start()\n",
    "    server.wait_for_termination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2574d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseInput(modelInput, typeString):\n",
    "    if \"tensor\" in typeString:\n",
    "        if \"float\" in typeString:\n",
    "            return onnxruntime.OrtValue.ortvalue_from_numpy(np.array([modelInput]).astype(\"float32\"))\n",
    "        if \"string\" in typeString:\n",
    "            return onnxruntime.OrtValue.ortvalue_from_numpy(np.array([modelInput]).astype(\"string\"))\n",
    "\n",
    "def curateInputs(session, modelInput):\n",
    "    inputs = {}\n",
    "    sessionInputs = session.get_inputs()\n",
    "    for i in range(0, len(sessionInputs)):\n",
    "        param = ast.literal_eval(modelInput)[i]\n",
    "        inputs[sessionInputs[i].name] = parseInput(param, sessionInputs[i].type)\n",
    "    return inputs\n",
    "\n",
    "def curateOutputs(session):\n",
    "    outputs = []\n",
    "    for o in session.get_outputs():\n",
    "        outputs.append(o.name)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve(port=5125, maxWorkers=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517fbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(\"QmXQpupTphRTeXJMEz3BCt9YUF6kikcqExxPdcVoL1BBhy\")\n",
    "o = session.run(curateOutputs(session), curateInputs(session, \"[[0.1,0.2,0.3]]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "eb1da31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051708132"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c42a346e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<onnxruntime.capi.onnxruntime_pybind11_state.ModelMetadata at 0x7ff3e3081b70>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_modelmeta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53fc657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(\"Volatility.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "10089a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 3]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_inputs()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e0c10978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-91-04487e7bb7ab>:1: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  np.fromstring('[1,2]', dtype=\"float32\", sep=',')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fromstring('[1,2]', dtype=\"float32\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4edfc2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensor(float)'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.get_outputs()[0].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2536df6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
