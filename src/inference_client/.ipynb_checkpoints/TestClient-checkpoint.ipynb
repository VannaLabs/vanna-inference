{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b60eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import sys\n",
    "import inference_pb2_grpc as pb2_grpc\n",
    "import inference_pb2 as pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f32f5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile proto3 file\n",
    "# python3 -m grpc_tools.protoc --proto_path=. ./inference.proto --python_out=. --grpc_python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "003941c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestClient(object):\n",
    "    \"\"\"\n",
    "    Client for testing inference gRPC\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        #self.host = '3.139.238.241'\n",
    "        self.host = 'localhost'\n",
    "        self.server_port = 5125\n",
    "\n",
    "        # instantiate a channel\n",
    "        self.channel = grpc.insecure_channel(\n",
    "            '{}:{}'.format(self.host, self.server_port))\n",
    "\n",
    "        # bind the client and the server\n",
    "        self.stub = pb2_grpc.InferenceStub(self.channel)\n",
    "\n",
    "    def send(self, tx, modelHash, modelInput):\n",
    "        \"\"\"\n",
    "        Client function to call the rpc for inference\n",
    "        \"\"\"\n",
    "        message = pb2.InferenceParameters(tx=tx, modelHash=modelHash, modelInput = modelInput)\n",
    "        print(f'{message}')\n",
    "        return self.stub.RunInference(message)\n",
    "    \n",
    "    def pipeline(self, tx, seed, pipelineName, modelHash, modelInput):\n",
    "        \"\"\"\n",
    "        Client function to call the rpc for inference\n",
    "        \"\"\"\n",
    "        message = pb2.PipelineParameters(tx=tx, seed=seed, pipelineName=pipelineName, modelHash=modelHash, modelInput = modelInput)\n",
    "        return self.stub.RunPipeline(message)\n",
    "\n",
    "def testLinearModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"LinearTest\", modelInput=\"[[1.0, 2.0, 3.0], [2.5, 3.5, 4.5]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "\n",
    "def testVolatilityModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"Volatility.onnx\", modelInput=\"[[0.03],[0.05],[0.04056685],[0.03235871],[0.05629578]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testXGBSpreadModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"XGBSpreadModel\", modelInput=\"[[0.003], [0.005], [0.004056685]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "\n",
    "def testLassoSpreadModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"QmXQpupTphRTeXJMEz3BCt9YUF6kikcqExxPdcVoL1BBhy\", modelInput=\"[[0.003, 0.005, 0.004056685]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testPipeline():\n",
    "    client = TestClient()\n",
    "    result = client.pipeline(tx = \"0x123\", seed=\"2\", pipelineName=\"text-generation\", modelHash=\"gpt2-xl\", modelInput=\"Please write me a poem about crypto?\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testClusteringModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"kmc.onnx\", modelInput=\"[[0.001410,0.003477,0.007010]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')\n",
    "    \n",
    "def testVolModel():\n",
    "    client = TestClient()\n",
    "    result = client.send(tx = \"0x123\", modelHash=\"QmcDnBi5PT223FmELECbZVTjitFUtTvaBoctDP88ESuAK4\", modelInput=\"[[0.003, 0.005, 0.004056685]]\")\n",
    "    print(\"Querying \" + client.host + \":\" + str(client.server_port) + \"...\")\n",
    "    print(f'{result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "381e5426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx: \"0x123\"\n",
      "modelHash: \"kmc.onnx\"\n",
      "modelInput: \"[[0.001410,0.003477,0.007010]]\"\n",
      "\n",
      "Querying localhost:5125...\n",
      "tx: \"0x123\"\n",
      "node: \"286f51bab25cb021d029128c9d1485303f2b6de6151564823249a474ba882ec288a8e01dc3208a872edc61a3824250ba8ffcf3606840130cd9c9d2533f6778c3\"\n",
      "value: \"1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testClusteringModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c15ebaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx: \"0x123\"\n",
      "modelHash: \"QmPqvT7n9savXmxEwFU7xNyFKTDBgVf2gQj1HAgabbcq9c\"\n",
      "modelInput: \"[[0.003, 0.005, 0.004056685]]\"\n",
      "\n",
      "Querying localhost:5125...\n",
      "tx: \"0x123\"\n",
      "node: \"09cd3f6ad2d813e5112da11babb82f8002dc82042d67c7b2ad2dc4fbd616e6334f1c822bdca54b124a6209dbff8e10db93b2cfda22924574dea0c06e89ec2eb2\"\n",
      "value: \"[0.00274395]\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testVolModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "389eb2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx: \"0x123\"\n",
      "modelHash: \"QmZiVM6vkk3ncQzxDXQAvjb5fiGcvVS6dmRi3wFwaGBzKE\"\n",
      "modelInput: \"[[0.003, 0.005, 0.004056685]]\"\n",
      "\n",
      "Querying localhost:5125...\n",
      "tx: \"0x123\"\n",
      "node: \"6b52b079355b7bd9aad673917514a28bd52a2fa7582d8b02f910cbb11e4a0995920eccd65985eddc83f095a984c0343a6c0cca2bab2be6503d331435ba701e49\"\n",
      "value: \"0\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testLassoSpreadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d8aede",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
